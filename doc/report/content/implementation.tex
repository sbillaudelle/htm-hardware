%\subsection{Rate Based Static Spatial Pooler}
%
%\subsubsection{Network Description}
%
%\begin{figure}
%	\begin{center}
%		\includegraphics{../circuitry/spatial_pooler.pdf}
%	\end{center}
%	\caption{Implementation of the spatial pooling algorithms. Columns \emph{C} are implemented utilizing a single neuron, while the inhibitory pool \emph{I} is modeled as a population consisting of e.g. 5 neurons. Projection \protect\circled{green}{1} represents the sparse excitatory connection from the input vector to the columns. At the same time, the global inhibitory pool is stimulated through forward connections \protect\circled{green}{2} from the source vector. Thus, the columns' overall activity is limited by this feed forward inhibition \protect\circled{green}{3}. A recurrent self-excitation \protect\circled{green}{4} facilitates enduring activation of single columns. A lateral inhibition with a predefined radius \protect\circled{green}{5} fosters a sparse column activity.}
%	\label{fig:static_spatial_pooler}
%\end{figure}
%
%A static version of the spatial pooler can be implemented as a self-normalizing competitive neural network, as shown in figure~\ref{fig:static_spatial_pooler}. Each column is represented by a single cell which is stimulated by a random subset of the input vector's bits. Active columns inhibit their neighbors within a radius $r_\text{inh}$. This lateral inhibition leads to a sparse activation of columns. At the same time, active columns recurrently stimulate themselves and thus try to stay in their active state.
%
%Furthermore, a feed-forward inhibition was added to the network. An inhibitory cell pool collects events from the input vector as a whole. Thus, the pool's activity correlates directly with the number of active input bits. Inhibitory projections to the individual columns dampens the their activity and therefore limits the number of active columns.
%
%In contrast to previous, purely software-based implementations, this model is not based on discrete computational steps. Instead, the continuous simulation is artificially divided into time steps of period $T_\text{step}$. A cell's or column's active state is defined by a series of spikes within a time step. This \emph{rate coding}-based approach limits the amount of information carried by a single event and thus should improve the noise resistance of the model. Similarly, the state of the input vector must be translated into spike trains. Each bit of the vector is assigned an individual spike source. For a true bit, the corresponding source emits a spike train of frequency $\nu_\text{stim}$. False bits are represented by a silent source. To avoid synchronization of the network, random jitter is added to the individual spike times.
%
%The implementation's default parameters are summarized in table~\ref{tab:static_spatial_pooler_defaults}. The spatial pooler's basic properties were verified with the given parameter set.
%
%\begin{table}
%	\begin{tabularx}{\textwidth}{lrX}
%		\toprule
%		Parameter & Default Value & Comment \\
%		\midrule
%		number of columns & 1000 & \\
%		size of inhibitory pool & 10 & \\
%		input vector size & 2000 & \\
%		\midrule
%		$w_\text{stim. → column}$ & 0.0066 & connection probability of 0.02 \\
%		$w_\text{stim. → pool}$ & 0.0035 & connection probability of 0.8 \\
%		$w_\text{global inh.}$ & 0.0024 & connection probability of 0.8 \\
%		$w_\text{recurrent}$ & 0.02 & \\
%		$w_\text{lateral inh.}$ & 0.008 & inhibition radius of 10 \\
%		\bottomrule
%	\end{tabularx}
%	\caption{Default parameters for the static spatial pooler implementation including population sizes as well as connection weights.}
%	\label{tab:static_spatial_pooler_defaults}
%\end{table}
%
%\subsubsection{Verification of Spatial Pooler Properties}
%
%\begin{figure}
%	\begin{center}
%		\input{assets/sparsity.pgf}
%	\end{center}
%	\caption{Number of active columns depending on the number of active cells of the input vector. While the output sparsity of course correlates with the input activity, a sufficient plateau is reached for a wide range of input activity counts.}
%	\label{fig:static_spatial_pooler_sparsity}
%\end{figure}
%
%\begin{figure}
%	\begin{center}
%		\input{assets/overlap.pgf}
%	\end{center}
%	\caption{Foobar}
%	\label{fig:static_spatial_pooler_overlap}
%\end{figure}
%
%The basic properties of the spatial pooler were verified for this implementation. For this purpose, the model was instantiated with 1000 columns and an input vector of length 2000\footnote{The limited input vector size is a result of the trade-off between the model's fidelity and the simulation's run time.}.
%
%In a first scenario, input patterns with overlap scores between 0.0 and 1.0 were presented to the network. The overlap score of the column's activity patterns was calculated and plotted against the corresponding input scores. As shown in figure~\ref{fig:static_spatial_pooler_overlap}, …
%
%In order to verify a sparse column activity, the network was stimulated with input data of varying sparsity. As a response, the number of active columns stayed the same for a wide range of active input bits, as is depicted in figure~\ref{fig:static_spatial_pooler_sparsity}.

\subsection{Static Spatial Pooler}

\begin{figure}
	\begin{center}
		\includegraphics{../circuitry/spatial_pooler_2.pdf}
	\end{center}
	\caption{Timing based implementation of the spatial pooler. Each column is represented by a single cell \emph{C} and receives sparse input \protect\circled{green}{1} from the input vector. Depending on the number of connected active input bits, a column reaches its firing threshold after a certain delay: cells receiving a higher number of presynaptic events will reach that threshold earlier. The inhibitory pool \emph{I} accumulates the number of active columns on its membrane \protect\circled{green}{2}. After a predefined number of active columns, the cell inhibits all columns \protect\circled{green}{3}.}
	\label{fig:spatial_pooler}
\end{figure}

At its core the spatial pooler resembles a \gls{kwta} network: $k$ out of $n$ columns are chosen to be active for each time step. In fact, \gls{kwta} networks have often been mentioned as an approximation for circuits naturally occurring in the neocortex \citep{felch2008hypergeometric}. While this topic has been discussed broadly and continuous-time as well as VLSI implementations were investigated \citep{erlanson1991analog,tymoshchuk2012,maass2000neural}, the requirements leading to this particular solution go beyond the discussed network architectures.

\subsubsection{Network Description}

The network presented in figure~\ref{fig:spatial_pooler} follows a purely timing-based approach designed for \gls{lif} neurons. It allows for very fast decision processes based on a single input event per source. Each column is represented by a single cell which accumulates feed-forward input from the spike sources. Here, the rise time of the membrane voltage decreases with the number of presynaptic events seen by the cell: cells receiving the most input will fire first. A inhibitory pool consisting of a single cell collects the network's activity. Low membrane and high synaptic time constants lead to a reliable summation of events. When a certain number of spikes have been collected -- and thus the threshold has been crossed --, the pool strongly inhibits all cells of the network suppressing following events.

The model is extended by adding subtle feed-forward shunting inhibition. The inhibitory conductance increases with the overall input activity $\nu_\text{in}$. Since the reversal potential is configured to match the leakage potential, the conductance contributes to the leakage term

\begin{align*}
	g_\text{l}' &= g_\text{l} + g_\text{inh}(\nu_\text{in})\..
\end{align*}
%
thus increasing the membrane time constant. This effectively slows down the neurons' responses and thus prolongs the decision period of the network.

Tie situations between columns receiving the same number of presynaptic events can be resolved by adding slight gaussian jitter to the weights of the excitatory feed-forward connections. This gives some columns structural advantages over other columns resulting in a faster response to the same stimulus. By increasing the standard deviation $\sigma_\text{j}$ of the jitter, the selection criterion is softened.

The proposed \gls{kwta} architecture was developed with the spatial pooler's properties in mind. In the following paragraphs, the model's performance is examined and compared to the goals formulated in section~\ref{sec:spatial_pooler_properties}.

\subsubsection{Verification of Spatial Pooler Properties}

The spatial pooler properties were investigated for a network spanning 1,000 columns and an input vector of size 10,000. To speed up the simulation, the input vector was multiplied to the feed forward connectivity matrix yielding a vector $\vec{l}$ containing the number of active inputs per column. This allowed to simulate the model with only 1,000 spike sources. Each source was configured to emit $l_i$ normally distributed events distributed within a very small time window, simulating the same number of coincident events from multiple input vector elements.

A first experiment was designed to verify the basic \gls{kwta} functionality. A random pattern was presented to the network. The number of active inputs per column -- the input overlap score -- can be visualized in a histogram as shown in figure~\ref{fig:spatial_pooler_activity}. By highlighting only the active columns, one can investigate the network's selection criteria. Complying with the requirements for a spatial pooler, only rightmost bars -- representing columns with the highest input counts -- are highlighted. Furthermore, the model's capability to resolve ties between columns receiving the same input counts is demonstrated: the bar at the decision boundary was not selected as a whole but only a few columns were picked. This verifies spatial pooler property~\ref{enm:spatial_pooler_selection}.

In a second scenario, input vectors with varying sparsity were fed into the network, as shown in figure~\ref{fig:spatial_pooler_sparsity}. The number of active columns stays constant across a wide range of input sparsity. Additionally the plot shows that columns must receive a minimum amount of input to become active at all. This verifies the underlaying \gls{kwta} approach as well as spatial pooler properties~\ref{enm:spatial_pooler_sparsity} and~\ref{enm:spatial_pooler_minimum}.

To verify the general functionality of a spatial pooler, expressed in property~\ref{enm:spatial_pooler_overlap}, a third experiment was set up. We generated input data sets with a variable overlap starting from an initial random binary vector. For each stimulus, the overlap of the columnar activity with the initial dataset was calculated while sweeping the input's overlap. The resulting relation of input and output overlap scores is shown in figure~\ref{fig:spatial_pooler_overlap}. Also included are the results of a similar experiment performed with a custom Python implementation of the spatial pooler directly following the original specification \citep{numenta2011htm}. In general, the curve yielded by the \gls{lif}-based implementation matches well with the algorithmic version of the model. However, maximal and minimal overlap scores are not reached for extreme input values $0.0$ and $1.0$.

\begin{figure}
	\begin{center}
		\input{assets/spatial_pooler/histo/activity.pgf}
	\end{center}
	\caption{Histogram showing the distribution of overlap scores individual columns see. Active columns are highlighted in this plot, showing that the $k$ columns with the most input were successfully selected.} 
	\label{fig:spatial_pooler_activity}
\end{figure}

\begin{figure}
	\begin{center}
		\input{assets/spatial_pooler/sparsity/sparsity.pgf}
	\end{center}
	\caption{The columnar sparsity is shown as a dependency of the input vector's sparsity. The highlighted range contains data points deviating not more than \SI{10}{\%} from the target sparsity of \SI{4}{\%}. Error bars indicate the standard deviation across five trials. The number of active columns stays constant for a broad range of input sparsity, thus fulfilling one of the basic requirements of the spatial pooler.} 
	\label{fig:spatial_pooler_sparsity}
\end{figure}

\begin{figure}
	\begin{center}
		\input{assets/spatial_pooler/overlap/overlap.pgf}
	\end{center}
	\caption{Output overlap as a dependency of the input vector's overlap. Similar input gets mapped to similar output patterns, while disjunct input results in low overlap scores.} 
	\label{fig:spatial_pooler_overlap}
\end{figure}

\subsection{Static Temporal Memory}

\begin{figure}
	\begin{center}
		\includegraphics{../circuitry/column.pdf}
	\end{center}
	\caption{Implementation of the temporal memory not including plasticity. Every HTM cell within a column is modeled with three individual LIF cells modeling different compartments (distal dendrites \emph{D}, soma \emph{S} and a lateral inhibition segment \emph{I} -- which is not biologically inspired). Per column, there exist multiple cell triples as well as one ``head'' cell \emph{P} which participates in the columnar competition and collects proximal input for the whole column. Activity of this cell is forwarded to the individual soma cells of the column \protect\circled{green}{1}. Without a previous prediction, this results in all soma cells firing. However, the distal compartment sums over the input of the previous time step. With a threshold being reached, the inhibitory compartment is depolarized by forwarding an event on \protect\circled{green}{3}. Together with proximal input \protect\circled{green}{2}, the inhibitory partition fires and inhibits all other cells in the column \protect\circled{green}{4}.}
	\label{fig:static_temporal_memory}
\end{figure}
