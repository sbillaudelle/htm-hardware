Implementing machine intelligence algorithms as spiking neural networks and
porting them to a neuromorphic hardware platform presents high demands in terms
of precision and scalability.

We have shown in this paper that \glspl{htm} can be successfully modeled in
dynamic simulations. The basic functionality of spatial pooler and temporal
memory networks could be reproduced based on \gls{adex} neurons. In theory, the
proof of concept networks can be easily transferred to the \gls{hmf}, since the
high-level software interfaces are designed to be interchangable. Of course,
emulating the models on the actual hardware platform will bring up a new set of
challenges.

Adapting the \gls{htm}'s learning rules to the native plasticity features
available on the \gls{hmf} has turned out to be nontrivial. The learning rules
could not be replicated with the current implementation of classic \gls{stdp}.
As a freely programmable microprocessor directly embedded into the neuromorphic
core, the \gls{ppu} provides the ability to extend the system's plasticity
mechanisms in order to implement the \gls{htm} rules. Further investigation is
required to map out a complete implementation of the \gls{htm} update rules on
the \gls{ppu}.

Analog neuromorphic hardware is susceptible to transistor mismatches due to e.g. dopand fluctuations in the production process \citep{petrovici2014characterization}. A careful calibration of the individual neurons is required to compensate for these variations. Due to the complexity of the problem and the high number of interdependent variables, a perfect calibration is hard to accomplish. Therefore, network models are required to be tolerant regarding certain spatial, and trial-to-trial variations on the computing substrate. Carrying out additional Monte Carlo simulations with slightly randomized parameters is important to investigate the robustness of the presented networks.

Finally, a multicompartmental neuron model is planned for a later version of the neurmorphic platform. Making use of this extended feature set will significantly increase the level of biophysical detail. This will account for the detailed dendritic model used in \glspl{htm} and help to stay closer to the whitepaper as well as the reference implementation.

Besides paving the road towards a highly accelerated execution of \gls{htm}
models, the \gls{hmf} offers a high level of detail in its neuron
implementation. With the multicompartmental extension and a flexible plasticity
framework, we anticipate the platform will prove valuable as a tool for
further low-level research on \gls{htm} theories.
